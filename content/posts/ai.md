+++
title = "Apple, AI, and Crypto"
description = "My opinion on few important things"
date = 2025-11-12T00:00:00Z
updated = 2025-11-12T00:00:00Z
draft = false
+++

I wanted to talk about my opinion on 4 things.

### 1. The .com bubble and AI economy
During the late 90s and early 2000s, .com boomed. Any solution, you put it on the internet with a .com bubble, and you most probably would be funded. This bubble burst, but .coms became the internet norm, although there are other TLDs.

Is the same happening for AI right now? Because any company saying AI in their solution description is getting funded, I don't know how. For example, this [company](https://x.com/ycombinator/status/1988366241460089118) recently got funded from YC. Although I do not care about YC companies these days, this is a new low.

Money keeps rotating between Nvidia, OpenAI, Google, etc Are they trying to grow the AI ecosystem this way? Although AI is something that I feel will change the way we work with things. It's really powerful, and I will say that this happening is the same as the Internet. Sure, people are misusing the Internet a lot for bad things; But, think of all the useful things we do on the Internet, lives being saved, relationships being created, even you reading this article.

### 2. State of Crypto

Crypto was in a boom in the mid-late 2010s, but why did we shift towards AI? The concept/working of crypto is great; we would immediately think of many use cases where crypto feels perfect. What I mean is, any Crypto is basically a blockchain, and the main selling point of blockchain is trust, transparency, and immutability. One can see all other transactions, and no one can change what's been written in the blockchain. Also, in order to write something to the blocks, people need to verify this transaction, which increases the trust as well as rewards the verifier (with coins).

This could have been used by the government, banking sector, education sector, etc I have a few possible answers to this question.

1. Limited knowledge: In order to use and trust this process, people need to understand what and how blockchain works. It's an added layer of action items for the consumer.
2. Scalability: Although the idea of blockchains sounds great, they do need more effort to cater to a large audience. It could be done; again, it's an action item for the people adopting it.
3. High Costs: Networks like Bitcoin are built on proof-of-work, meaning other people need to verify a transaction in order to increase the trust of that transaction. The problem is to verify a transaction; the person verifying needs to solve complex math problems, which require GPUs and electricity.
4. Trust: Although blockchain is trustable by design, vulnerabilities in smart-contracts cause hacking incidents which leads to losses in high value. I everyday read about some hack in a network which caused millions of dollars to be stolen. How will an average consumer trust this? I believe this is one of the main reasons.


Now, if you compare crypto with AI, the AI boom is much quicker and has been adopted immediately by consumers as well as companies. AI doesn't add an extra layer of learning to the consumer; it just makes things easier (for an end consumer). Also, the use cases are in everyday things: starting from to-do apps to healthcare. I lean more towards AI, which led me to start learning "Deep Learning".

### 3. Apple and AI

Apple promised "Apple Intelligence" with the iPhone 16 release, but hasn't talked about it after that. Why is Apple behind in the AI race? It is leaning on Gemini or ChatGPT for AI assistance. I see people saying Apple is not able to develop models. But I still question myself, a company of this caliber, creating world-class products, not able to develop models and integrate them with its own products? That does not seem like a very strong reason to me. I do not know the answer to this question, but I still imagine a few things:

1. Data privacy: Apple is a very private company, meaning it is very careful with users' data (at least better than Google). To have AI features integrated into a product, there needs to be a model. The model can exist either in the cloud or on the device. If the model needs to exist on the device, it must be powerful enough to run with the current and previous gen hardware. Even if Apple wants to integrate that in upcoming devices, they might have to give up on battery or performance. This is because, for a given price point, the company will not (most probably) give everything to a user.

 Even for LLMs on the cloud, the problem is that data cannot be end-to-end encrypted for LLMs, which means Apple will have to see your personal data. This might break the differentiation between Apple and others.
 
 For LLMs on the device, the data stays on the device. So, it's not a security problem but a hardware one. The device must be powerful enough to handle the model and cheap enough for the consumer to even think of buying.
 
2. AI Scientists: Recently, Meta poached employees from OpenAI and even Apple to accelerate AI research, offering up to 100 million dollars. I am not sure if Apple has any AI scientists who are committed enough to make things work. Even worse, people are leaving Apple for Meta, OpenAI, etc...

I somehow believe in Apple. The main reason is that they usually aren't the first to come into the picture. But when they do, they are always the best in that category. A few examples I can remember are iPhone (Blackberry was at its peak), M chips (When Apple started doing its own chips instead of sourcing them from Intel), Airpods (Looks similar to other earphones, but when you put it on, it is completely different).

Why does Apple do this? For a company as big as Apple, it doesn't matter if they arrive first at a problem. They suddenly appear with a solution but it might be something that a normal person wouldn't even think of as a solution. Taking the iPhone as an example, there were phones during that time. Blackberry was at peak, phones with keyboards were the trend. Launching a phone without a keyboard and without a stylus seemed crazy then, became normal today.


### 4. Future of AI and agents

You can define an Agent as a software that uses AI to make decisions with minimal human interaction. This is a fascinating topic because it automates things we thought could not be automated, at least in the near future (like booking a flight, shopping, etc). It might not be perfect right now, but we have started.

The problem with continuous AI agents is the data. The companies will have complete control of what we see and do; it sounds very uncomfortable to me. I tried the Comet browser, and it was great. But I was not comfortable with its data policy. So, back to Brave!

If you dig deeper, you might see that Agents and RAG are a wrapper on top of LLMs. But they are being sold with aesthetics and whatnot. Many AI solutions are just LLM wrappers (which is not bad), but it would be better if they mentioned the limits of agents. Anyhow, they solve a new-age problem "context".

Some people do not like the influence of AI, as it is doing people's jobs and thinking that life was much simpler before AI. I guess people have to adapt to the fast-moving changes. I worry for people who are not interested in adapting (which is okay), being forced to adapt to the AI changes. I also feel for the people whose jobs were taken by AI. It's hard, but learning and adapting are the constant things to do to stay relevant. Also, learning AI is interesting and fascinating.
